{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EjectionFractionPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirbhik-datta/CrimesInCommunities/blob/master/EjectionFractionPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGyN88j1Fp2k",
        "colab_type": "text"
      },
      "source": [
        "#Ejection Fraction Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNE8ELOjn7Ts",
        "colab_type": "text"
      },
      "source": [
        "###Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLkHmhrVgg09",
        "colab_type": "text"
      },
      "source": [
        "The deterioration of cardiac function is a key indicator of heart disease. To determine this functionality, doctors measure the end-systolic and end-diastolic volumes. These measurements are used to determine the EF (Ejective Fraction). The ejective fraction is the percentage of blood ejected from the left ventricle with each heartbeat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx49ccr1MvYg",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://storage.googleapis.com/kaggle-competitions/kaggle/4729/media/heart-illustration2-resized.jpg)\n",
        "\n",
        "(https://www.kaggle.com/c/second-annual-data-science-bowl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0s5kCOXNtAg",
        "colab_type": "text"
      },
      "source": [
        "Dataset comprised of cardiac MRI images of 1000 patients. Images compiled by NIH and Children's National Medical Center. Dataset known as the Sunnybrook Cardiac Data (SCD) or as 2009 Cardiac MR Left Ventricle Segmentation Challenge data. Segmentation challenge consists of accurate dilineation of endocardial (inner heart tissue) and epicardial (outer heart layer) contours of the left ventricle (LV). Manual dilineation is time consuming / tedious and may vary depending on observer.\n",
        "\n",
        "Four main challenges associate with automatic segmentation of LV using cine MRI:\n",
        "* overlap between intensity distributions within cardiac regions\n",
        "* lack of edge information\n",
        "* shape variability between endocordial and epicardial slices / phases (inner and outer slices of heart)\n",
        "* variability of these factors from subject to subject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcHto9iMON_c",
        "colab_type": "text"
      },
      "source": [
        "Goal of contest is to compare LV segmentation with expert contours. Contest provides open-source code for contour evaluation. Metric for evaluation is Continuous Ranked Probability Score. For each MRI, predict the cummulative probability of distribution for both systolic and diastolic volumes.\n",
        "\n",
        "https://www.midasjournal.org/browse/publication/658"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLVcNEMthzuY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "###Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09qu7OrVh5LJ",
        "colab_type": "text"
      },
      "source": [
        "The dataset consists of 45 cine-MRI images four main pathological groups:\n",
        "* Heart Failure with infarction(HF-I) (EF < 40% and evidence of Gd enhancement)\n",
        "* Heart Failure without infarction(HF) (EF < 40% and no evidence of Gd enhancement)\n",
        "* LV Hypertrophy(HYP) (normal EF (EF > 55%) and ratio of left ventricular (LV) mass over body surface area is > 83 g/m^2)\n",
        "* Healthy group(N) (had normal EF and no Hypertrophy)\n",
        "\n",
        "(Gd enhancement - Indicator of adverse cardiovascular outcomes)\n",
        "(LV Hypertrophy - Thickening of heart walls of main heart pumping chamber)\n",
        "\n",
        "http://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-ABbdpC8Hc",
        "colab_type": "text"
      },
      "source": [
        "### Potential Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5UXTiwaDCpA",
        "colab_type": "text"
      },
      "source": [
        "U-Net : CNNs for Biomedical Image Segmentation\n",
        "* For biomedical image processing, issue is images for training not easily accessible\n",
        "* Builds on fully convolutional layer - modified to work on few training images and yield more precise segmentation\n",
        "* Given little data, model uses data augmentation by applying elastic deformations on the available data\n",
        "* Starts with contracting path for context, ends with symmetric expanding path for precise localization\n",
        "* Biomedical image processing - desired input should include image localization (class label assigned to each pixel); number of training images rarely reaches 1000s\n",
        "* Sliding window + patches inefficient due to overlapping patches; also has trade off between localization and use of context\n",
        "* This model builds on FCN (below) - builds on to train on few examples and yield more precise segmentaiton\n",
        "* Main idea of FCN - use contracting network where pooling operator replaced by upsampling (increases resolution of output); use skip connections to learn low-level features of data\n",
        "* Modification to FCN - include large number of feature channels to allow for propagation of context to high resolution -> resulting network has expansive section with symmetric shape to contracting section (U-shaped)\n",
        "* Use little training data - use excessive data augmentation by applying elastic data elastic deformations to available images\n",
        "* Allows network to learn invariance to such deformations\n",
        "\n",
        "--Network Architecture\n",
        "* Contracting path (left) and expansive path (right)\n",
        "* Contracting path - repeated application of 2 3x3 convolutions (unpadded) followed by ReLU; 2x2 max-pooling with stride of 2 for downsampling (each downsample, double the feature channels)\n",
        "* Expansive path - every step upsampling of feature map followed by 2x2 convolution (halves feature channel); then followed by concatenation with corresponding cropped (prevent loss of border pixels) feature map from contracting path (skip connection) + 2 3x3 convolutions with ReLU activation after\n",
        "* Final layer has 1x1 convolution to map 64-component vector to desired number of classes (total of 23 convolutional layers)\n",
        "* To allow tilting of output segmentation map (allow focus a subimage), even x and y input size\n",
        "\n",
        "--Training\n",
        "* Input image and corresponding segmentation map used to train network used to train network using SGD implementation of Caffe\n",
        "* Energy function computed using pixel-wise softmax over final feature map combined with cross-entropy loss function ?\n",
        "* Pre-compute weight map of ground truth segmentation to compensate the different frequency of pixels of a certain class to allow for seperation of touching objects of same class\n",
        "* Weight initialization using Gaussian Distribution with standard deviation of sqrt(2/N) where N = number of incoming nodes of one neuron\n",
        "* Further details in paper\n",
        "\n",
        "--Data Augmentation\n",
        "* Data augmentation important to teach desired invariance and robustness properties with few training examples\n",
        "* For microscopial images, need shift and rotation invariance as well as robustness to deformation and grey value variations\n",
        "* Random elastic deformities key for segmentation with few images\n",
        "* Smooth deformations applied by using random displacement vectors on coarse 3x3 grid; displacements sampled from Gaussian distribution with 10 pixel standard deviation; per-pixel displacement then computed using bicubic interpolation (extension of cubic interpolation in 2D); dropout layers at end of contracting path allow for implicit data augmentation\n",
        "\n",
        "https://arxiv.org/pdf/1505.04597\n",
        "\n",
        "U-Net Implementation, trained network and more information:\n",
        "https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3PqLqHGETLb",
        "colab_type": "text"
      },
      "source": [
        "Fully Convolutional Networks for Semantic Segmentation\n",
        "* Pixel level prediction - natural progression from coarse inference to fine inference\n",
        "* Semantic Segmentaiton - each pixel labled with the class of its enclosing object (has shortcommings addressed with the paper)\n",
        "* Paper shows Fully convolutional network (FCN) trained end to end exceeds state-of-art without need for further machinery - from supervised pre-training for pixel-wise prediction\n",
        "* whole-image-at-a-time forward and backprop\n",
        "* in-network upsampling allows for pixelwise-prediction and learning with nets using subsampled pooling\n",
        "* Semantic Segmentation inherently has tension with semantic and location - global info resolves what while local info resolves where - use skip architecture to make use of feature spectrum (local-to-global pyramid)\n",
        "* Convnets built on translation invariance - basic operations operate on local input regions and depend on local relative spatial coordinates\n",
        "* Layer by layer computation faster than patch-by-patch (looking at subimages) due to overlapping fields\n",
        "* Typical recognition nets (LeNet , AlexNet) take fixed sized inputs and produce non-spatial outputs - fully connected layers have fixed dimensions and throw away spatial coordinates\n",
        "* Treating FC layers as convolutions with kernals covering entire image allows you to take input of any size and output a classification map\n",
        "* Replacing FC with convolutions using filters allow for faster computation; reduce output size using subsampling (also keeps filters small)\n",
        "* Connect coarse output to dense pixel using interpolation\n",
        "* Can interpolate by factor f with \"backward convolution (deconvolution)\" with output stride f (easily implemented by reversing forward and backward passes of convolution)\n",
        "\n",
        "\n",
        "--Segmentation Architecture\n",
        "* Cast ILSVRC classifiers (for object detection / image detection) into FCNs and augment them for dense prediction with innetwork upsampling and pixelwise loss - train for segmentation by fine tuning; utilize skip connections to fuze coarse, semantic info and local, appearance info (Figure 3 in paper below)\n",
        "* Train with per-pixel multinomial logistic loss (soft-max) - validate with mean pixel IoU (overlap between target and predicted mask) - ignores pixels masked out in ground truth for being ambiguous/ difficult\n",
        "\n",
        "--From classifier to dense FCN\n",
        "* convolutionizing image classifiers - take models (AlexNet, GooLeNet, VGG) and remove final classification layer - appened a 1x1 convolution layer with dimension 21 to predict score of coarse output locations, followed by deconvolution layer to bilinearly upsample pixel coarse outputs to pixel dense outputs (bilinear upsampling = using nearby pixels to calculate pixel value using linear interpolation)\n",
        "* Get rid of issue with coarse segmentation using skips with lower layers with finer strides\n",
        "\n",
        "https://arxiv.org/pdf/1605.06211.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyCXSqAv8raa",
        "colab_type": "text"
      },
      "source": [
        "Caffe: Convolutional Architecture for Fast Feature Embedding\n",
        "* Framework for deep learning algorithms and models; Python and MATLAB bindings\n",
        "* By separating models by implementation\n",
        "* Allows usage of cloud\n",
        "* Caffe model definitions written in config files using Protocol Buffer language (similar to XML but more lightweight; used to structure serialized data)\n",
        "* Spurred by reproducable reserach\n",
        "\n",
        "--Architecture\n",
        "* Caffe stores and communicates using 4-dimensional arrays (blobs)\n",
        "* blobs provide unified memory interface - holds batch of images (or other forms of data), parameters, or parameter updates\n",
        "* Data storage - more info in paper\n",
        "* Layers  - Caffe layer takes on or more blobs as inputs and yields one or more blobs as outputs; responsible for forward pass (inputs to output) and backward pass(takes gradient with respect to output and computes gradient with respect to the parameters and inputs(which are backpropagated to earlier layers))\n",
        "* layer types includes convolution, pooling, inner-product, nonlinearities such as ReLU, local normalization, losses, etc.\n",
        "* Caffe models are end-to-end ML systems\n",
        "* Trains by fast and standard stochastic gradient decent\n",
        "* Vital to training - learning rate decay schedules, momentum and snapshots for starting and resuming\n",
        "* Finetuning - adaptation of existing model to new architecture or data); Caffe implements through snapshots of existing model and existing model definition - used to initialize old model weights for new tasks and intialize new weights as needed\n",
        "* Finetuning (finer adjustments to improve performance) vs Tranfer Learning (taking a previous model and using it for new task)\n",
        "\n",
        "More info regarding usage and tutorial in paper / website\n",
        "\n",
        "https://arxiv.org/pdf/1408.5093.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJXD6-PKYqbq",
        "colab_type": "text"
      },
      "source": [
        "PixelNet\n",
        "https://www.cs.cmu.edu/~aayushb/pixelNet/pixelnet.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc3ui3_AHQ8B",
        "colab_type": "text"
      },
      "source": [
        "Relevant Pieces for LV Segmentation Challenge\n",
        "* https://www.midasjournal.org/browse/publication/686\n",
        "* https://www.midasjournal.org/browse/publication/678\n",
        "* https://www.midasjournal.org/browse/publication/683\n",
        "* https://www.midasjournal.org/browse/publication/677\n",
        "* https://www.midasjournal.org/browse/publication/679\n",
        "* https://www.midasjournal.org/browse/publication/684\n",
        "* https://www.midasjournal.org/browse/publication/691"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jzC3gzroYFe",
        "colab_type": "text"
      },
      "source": [
        "###Other Terms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNuPGJVrI01",
        "colab_type": "text"
      },
      "source": [
        "Cine MRI\n",
        "\n",
        "* Cine studies obtained by repeatedly imaging the heart at a single slice location throughout the cardiac cycle\n",
        "\n",
        "* Multiple lines of k-space (echoes) can be acquired in a single heart beat - data from multiple heart beats used to fill this k-space matrix (further research needed)\n",
        "\n",
        "* To properly evaluate heart function, multiple slices at different locations needed\n",
        "\n",
        "http://mriquestions.com/beating-heart-movies.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2SOphsxobhJ",
        "colab_type": "text"
      },
      "source": [
        "DICOM (Digital Imaging and Communications in Medicine) - used to store, exchange, and transmit images.\n",
        "\n",
        "* Images have associated patientID\n",
        "* DICOM data object consists of number of attributes (name, ID, etc.)\n",
        "* Special attribute containing pixel data (typically single image but can consist of multiple frames - allowing for multi-frame data)\n",
        "* 3 data encoding schemes - GROUP, ELEMENT, VR (2 bytes each) for VRs not in OB, OW, OF, SQ, UT, or UN (VR =  value representation); if in this list, find the table in link below\n",
        "* Value multiplicity provides info regarding # of data elements for a given attribute (for string if multiple encoded successive data elements seperated by '\\' character\n",
        "* To display image, lookup table to display digitally assigned pixel values (allows for visual consistency) - DICOM greyscale standard display function (GSDF)\n",
        "* DICOM Part 10 files - offline files (futher info at link below)\n",
        "\n",
        "\n",
        "https://en.wikipedia.org/wiki/DICOM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO1TntdnKcvN",
        "colab_type": "text"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfNqnyzoKejN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/etc/apt/sources.list') as f:\n",
        "  txt = f.read()\n",
        "with open('/etc/apt/sources.list.backup', 'w') as f:\n",
        "  f.write(txt)\n",
        "with open('/etc/apt/sources.list', 'w') as f:\n",
        "  f.write(txt.replace('# deb-src','deb-src'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCvt0TfOeRxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}